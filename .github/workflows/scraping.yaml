name: Scraping the repositories from Source Graph

#on:
#  schedule:
#    # Trigger every day at midnight
#    # https://crontab.guru/#0_0_*_*_*
#    - cron: '0 0 * * *'

# TODO: split the commands to crapr repos and parse the dependencies
# TODO: a job for index generation
on: [push]

jobs:
  scraping:
    if: ${{ !github.event.act }} # skip during local actions testing
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11]
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"
          cache-dependency-path: "requirements/base.txt"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements/base.txt
      - name: Start scraping
        run: |
          python -m app.scrape
      - uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Scraped repositories from Source Graph"
